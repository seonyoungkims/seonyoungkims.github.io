<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Project: Efficient AI Deployment on NPUs</title>
  
  <link rel="stylesheet" href="../../styles.css">
  
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&family=Source+Sans+3:ital,wght@0,200..900;1,200..900&display=swap" rel="stylesheet">
</head>
<body>
  <main class="container">

    <h1 class="page-title">Efficient AI Deployment on NPUs</h1>

    <div classs="page-links">
      <a href="../../index.html#projects">‚Üê Back to Main</a>
    </div>

    <section class="project-detail">
      <img src="../../assets/images/Pr6.png" alt="Efficient AI Deployment on NPUs thumbnail" style="width:100%; max-width:600px; margin-bottom: 20px;">
      
      <h2>Project Overview</h2>
      <p>
        At Samsung Research, I research hardware-aware model compression techniques, such as ultra low-bit quantization, to enable efficient deployment on NPUs. My work spans large-scale models including LLaMA, Gemma, and speech models.
      </p>

      <h2>My Role & Contributions</h2>
      <ul>
        <li>Researched and implemented sub-4-bit quantization (e.g., 3-bit, 2-bit) algorithms.</li>
        <li>Analyzed hardware constraints of the NPU to develop co-designed optimization strategies.</li>
        <li>Achieved significant reduction in model size and latency for LLaMA models on target hardware.</li>
        </ul>

      <h2>Key Challenges & Solutions</h2>
      <p>
        One of the main challenges was...
      </p>

    </section>

  </main>
</body>
</html>
